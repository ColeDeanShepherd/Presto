token_type = union
    identifier
    number_literal
    fn_keyword
    record_keyword
    union_keyword
    if_keyword
    then_keyword
    else_keyword
    whitespace
    equals
    minus
    greater_than
    left_paren
    right_paren
    left_curly_bracket
    right_curly_bracket
    comma
    colon
    period

token = record
    _type: token_type
    _text: text
    position: text_position
    was_inserted: bool

tokenize_output = record
    tokens: list(token)
    errors: list(compile_error)

tokenize_state = record
    text_left: text
    position: text_position
    indentation_stack: list(nat)
    tokens: list(token)
    errors: list(compile_error)

is_done = fn (state: tokenize_state): bool -> eq(length(state.text_left), 0)
