TokenType = union {
    identifier
    number_literal
    fn_keyword
    record_keyword
    union_keyword
    trait_keyword
    if_keyword
    then_keyword
    else_keyword
    whitespace
    equals
    minus
    less_than
    greater_than
    left_paren
    right_paren
    left_curly_bracket
    right_curly_bracket
    left_square_bracket
    right_square_bracket
    character_literal
    comma
    colon
    period
    comment
    string_literal
    plus_sign
    forward_slash
    asterisk
    equality_operator
    right_arrow
    question_mark
    double_greater_than
}

Token = record {
    _type: TokenType
    text: Text
    position: TextPosition
    was_inserted: Bool
}

TokenizeOutput = record {
    tokens: Seq[Token]
    errors: Seq[CompileError]
}

TokenizeState = record {
    text_left: Text
    position: TextPosition
    indentation_stack: Seq[Nat]
    tokens: Seq[Token]
    errors: Seq[CompileError]
}

is_done = fn (state: TokenizeState): Bool -> length(state.text_left) == 0
is_not_done = fn (state: TokenizeState): Bool -> not(is_done(state))
get_current_indentation = fn (state: TokenizeState): Nat -> last_or_default[Nat](state.indentation_stack, 0)
#advance_text_position = fn (position: TextPosition, read_char: Char): TextPosition -> {
#    if not_eq(read_char, '\n') then
#        new_text_position(position.line_index, sum(position.column_index, 1))
#    else
#        new_text_position(sum(position.line_index, 1), 0)
#}