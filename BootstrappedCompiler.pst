token = record
    type: token_type
    txt: text
    position: text_position
    was_inserted: bool

tokenize_output = record
    tokens: list(token)
    errors: list(compile_error)

tokenize_state = record
    text_left: text
    position: text_position
    current_indentation: nat
    tokens: list(token)
    errors: list(compile_error)

is_done = fn (state: tokenize_state) -> eq(state.text_left.length, 0)
is_not_done = fn (state: tokenize_state) -> not(is_done(state))

advance_text_position = fn (position: text_position, read_char: char): text_position ->
    if not(eq(read_char, '\n')) then
        text_position(
            line_index = position.line_index,
            column_index = add(position.column_index, 1)
        )
    else
        text_position(
            line_index = add(position.line_index, 1),
            column_index = 0
        )